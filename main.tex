\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage[font=tiny,labelfont=bf]{caption}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1,1,1}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    numbers=none,
    basicstyle=\ttfamily\tiny,
    aboveskip=0pt, % Spazio sopra il codice
    belowskip=0pt, % Spazio sotto il codice
    lineskip=0pt  % Riduzione spaziatura tra le righe
}

\lstset{style=mystyle}

\usetikzlibrary{positioning, arrows.meta}

\usetheme{Boadilla}

\graphicspath{ {./pics} }

\title[Transfer learning e quantizzazione]
{Riconoscimento efficiente di immagini di animali tramite transfer learning e quantizzazione}
\subtitle{ML project a.y. 2024/2025}
\author[Stefano Belli, 0350116]{Stefano Belli, matricola 0350116}
\institute[uniroma2]{Università degli Studi di Roma "Tor Vergata"}
\date{}

\newcommand{\dflvspace}{\vspace{10pt}}

\renewcommand{\footnotesize}{\tiny}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{enumerate items}[default]

\colorlet{softgreen}{green!60!black} 

\newcommand{\nocross}{{\color{red} \ding{55}}}
\newcommand{\okmark}{{\color{softgreen} \ding{51}}}

\newcommand{\dnnarch}[1]{
    \tikzset{
    	node/.style={draw, minimum width=4.2cm},
    	data/.style={align=center, minimum width=4.2cm}
	}

	\begin{tikzpicture}[node distance=0.35cm, auto, >=latex]
  		\node[data](data) {\footnotesize immagine 319x319 RGB};
    	\foreach \nd/\td/\cd [remember=\nd as \Nd (initially data)] in #1 {
        	\node [node, align=center, fill=\cd, below=of \Nd] (\nd) {\td};
        	\draw[->](\Nd)--(\nd);
    	}
    	\node[data, below=of out] (Data) {\footnotesize vettore di 10 probabilità};
    	\draw[->](out)--(Data);
    	
	\end{tikzpicture}
}
	

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
    \frametitle{Agenda}
    \tableofcontents
\end{frame}

\section{Il problema da affrontare}
\begin{frame}
    \frametitle{Il problema da affrontare}
    
    %\fontsize{9pt}{10pt}\selectfont
    Si richiede di progettare un classificatore di immagini di animali tramite
    modelli preaddestrati, sfruttando il \textbf{transfer learning} e la \textbf{quantizzazione}.
    
    \dflvspace
    
    Per questo progetto, è importante tenere conto sia dell'\textbf{accuratezza} del modello
    che dei \textbf{costi computazionali}.
    
    \dflvspace
    
    Verranno confrontati due modelli con e senza
    quantizzazione tenendo conto delle seguenti metriche:
    
    \dflvspace
    
    \begin{itemize}
    	\item Loss e accuracy del modello
    	\item Tempo di inferenza del modello
    	\item Grandezza del modello ottenuto
    \end{itemize}
    
\end{frame}

\section{Transfer learning}
\begin{frame}
    \frametitle{Transfer learning}
    
    Addestrare modelli di deep learning in modo efficiente non è affatto semplice:
    \begin{enumerate}
    	\item Hardware potente e costoso richiesto
    	\item Tempi di addestramento del modello elevati
    	\item Costi per l'energia eccessivi
    	\item Mancanza di dati per l'addestramento
    	\item Progettare una rete da zero
    \end{enumerate}
    
    \dflvspace
    
    \begin{exampleblock}{Applicazione}
    E' possibile sfruttare modelli preaddestrati complessi, già testati e perfettamente funzionanti e "trasferirli" al
    nostro problema congelandone i pesi (\textit{"trained weights"}), lasciando "addestrabili" solo i pesi di una rete neurale densa che è il
    classificatore rimpiazzato dal nostro.
    \end{exampleblock}
\end{frame}

\section{DNNs e dispositivi embedded}
\begin{frame}
    \frametitle{DNNs e dispositivi embedded}
    
    Pensiamo all'IoT e alla diffusione capillare di dispositivi embedded, ad esempio una telecamera: e se volessimo
    integrare una rete convoluzionale nel device stesso?
    \begin{itemize}
    	\item Preserveremmo la privacy dell'utente
    	\item Niente problemi di latenze elevate o legate al trasferimento dati
    	\item Se la telecamera viene disconnessa da internet, la rete può continuare a svolgere il suo compito, rendendo il dispositivo
    	più affidabile
    \end{itemize}
    
    \dflvspace
    
    Il problema nell'eseguire le reti neurali su tali dispositivi è ovvia: la poca potenza a disposizione 
    impatta sui tempi di \textbf{inferenza} del modello e sulla \textbf{memorizzazione} 
    (sia in memoria primaria che secondaria) dei pesi del modello, oltre al fatto che il dispositivo potrebbe \underline{non avere
    capacità di calcolo in virgola mobile} (es. non ha una FPU o ISA che supporti operazioni floating point).

\end{frame}

\section{Quantizzazione}
\begin{frame}
	\frametitle{Quantizzazione}
	
	Una tecnica che consente di ridurre la dimensione dei parametri di un modello:
	\begin{itemize}
		\item Meno \textbf{storage} richiesto per mantenere i parametri della rete
		\item Reappresentare un parametro da \texttt{float} $\rightarrow$ \texttt{int8\_t} significa niente
		operazioni floating point e quindi \textbf{tempi} di inferenza minori
	\end{itemize}
	
	\dflvspace
	
	La tecnica non impatta significativamente sull'accuratezza del modello originale: l'alta precisione
	di un \texttt{float} o \texttt{double} probabilmente non è necessaria per far si che il modello
	svolga bene il suo lavoro.
	
\end{frame}

\subsection{Quantizzazione post-training}
\begin{frame}
	\frametitle{Quantizzazione post-training}
	
	In particolare, nel progetto viene utilizzato TFLite/LiteRT e
	quantizzazione post-training che permette di definire un modello Keras, 
	addestrarlo normalmente, e solo dopo quantizzarlo.
	
	\dflvspace
	
	Dopo aver convertito il modello, è possibile applicare 
	3 livelli di quantizzazione (incrementale)
	
	\dflvspace
	
	\begin{center}
	\begin{table}
	\begin{tabular}{|r|c|c|c|}
	\hline
	& \textbf{Param. fissati} & \textbf{Variabili} & \textbf{Tensori di I/O} \\
	\hline
	\hline
	\textbf{Dynamic range} & \okmark & \nocross & \nocross \\
	\hline
	\textbf{Float fallback} & \okmark & \okmark & \nocross \\
	\hline
	\textbf{Integer-only} & \okmark & \okmark & \okmark \\
	\hline
	\end{tabular}
	\caption{\okmark\;indica che avviene la quantizzazione, \nocross\;indica che non avviene}
	\end{table}
	\end{center}
	
\end{frame}

\section{Split del dataset}
\begin{frame}
    \frametitle{Split del dataset}
    
    Il dataset fornito consiste in immagini di animali con etichette associate (10 classi),
    pronto per essere letto e splittato da \texttt{keras.utils.image\_dataset\_from\_directory}.
    
    \dflvspace
    \dflvspace
    
    \begin{center}
    \begin{tikzpicture}
    
    	\draw (0,0) -- (10,0);
    	\draw (0,0) -- (0,1);
    	\draw (0,1) -- (10,1);
    	\draw (10,1) -- (10,0);
    	
    	\draw (6.5,0) -- (6.5,1) node[below, xshift=17pt, yshift=-27pt]{\tiny{Validation set (12\%)}};
    	
    	\draw (7.5,0) -- (7.5,1);
    	
    	\node at (3,0.5) {\tiny{Training set (68\%)}};
    	\node at (8.75, 0.5) {\tiny{Testing set (20\%)}};
    	
    \end{tikzpicture}
    \end{center}
    
    \dflvspace
    \dflvspace
    
    \begin{itemize}
    	\item Il \textbf{training set} viene utilizzato per l'addestramento dei modelli
    	\item Il \textbf{validation set} viene usato ogni 3 epoche di addestramento e mostrare esempi di predizione
    	\item Il \textbf{testing set} viene usato per effettuare le misurazioni finali
    \end{itemize}
    
\end{frame}

\section{Architettura dei modelli analizzati}
\begin{frame}
    \frametitle{Architettura dei modelli analizzati}
    
    I due modelli pretrained scelti sono \texttt{MobileNet} e \texttt{InceptionResNetV2},
    facilmente istanziati con i trained weights \texttt{imagenet} grazie a \texttt{keras.applications}
    
    \dflvspace
    \dflvspace
    
    \begin{tabular}{c c}
    
    \def\firstlayers{
    	a/\tiny{Rescaling in $$[\,-1\,\dots\,1\,]$$ - 0 - $319\times 319\times 3$ }/white,
    	b/\tiny{MobileNet - $3.3M$ - $10\times 10\times 1024$}/cyan,
    	c/\tiny{GlobalAvgPool - $0$ - $1024$}/white,
    	d/\tiny{Dropout di $0.25$ - $0$ - $1024$}/white,
    	out/\tiny{Dense (softmax) - $10k$ - $10$} /white}
    
	\dnnarch{\firstlayers}
	
	&
	
	\def\secondlayers{
    	a/\tiny{Rescaling in $$[\,-1\,\dots\,1\,]$$ - 0 - $319\times 319\times 3$ }/white,
    	b/\tiny{InceptionResNetV2 - $54.3M$ - $8\times 8\times 1536$}/cyan,
    	c/\tiny{GlobalAvgPool - $0$ - $1536$}/white,
    	d/\tiny{Dropout di $0.4$ - $0$ - $1536$}/white,
    	out/\tiny{Dense (softmax) - $15k$ - $10$} /white}
    
	\dnnarch{\secondlayers}
	
	\end{tabular}
    
\end{frame}

\section{Training}
\begin{frame}[fragile]
    \frametitle{Training}
    
    \begin{tabular}{l r}
    
    \begin{minipage}[t] {0.5\textwidth}
    \begin{lstlisting}[language=Python]
# you may override this
def compile_model(self, *args, **kwargs):
	self.model.compile(
		optimizer=keras.optimizers.Adam(),
		loss=keras.losses.CategoricalCrossentropy(),
		metrics=[
			keras.metrics.CategoricalAccuracy()
		])

# you may override this
def fit_model(self, *args, **kwargs):
	return self.model.fit(
		args[0],
		validation_data=args[1],
		validation_freq=3,
		epochs=40,
		callbacks=[
			keras.callbacks.EarlyStopping(
				start_from_epoch=3,
				patience=2,
				restore_best_weights=True),
			keras.callbacks.LearningRateScheduler(
				lambda e, l: l if e < 1 else l * np.exp(-0.15)
		)])
    \end{lstlisting}
    \end{minipage}
    
    &
    
    \begin{minipage} [t] {0.5\textwidth}
    		\fontsize{9pt}{10pt}\selectfont
    		
    		Compilazione del modello:
    		\begin{itemize}
      		\item Optimizer: adam
      		\item Loss: categorical crossentropy
      		\item Metrica d'interesse: categorical accuracy
     	\end{itemize}
     	
     	\dflvspace
     	\dflvspace
     	
     	E il suo addestramento:
     	\begin{itemize}
     		\item 40 epoche totali
     		\item Validazione ogni 3 epoche
     		\item Early stopping
     		\begin{itemize}
     			\item Pazienza 2
     			\item Partenza da epoca 3
     			\item Ripristino pesi migliori
     			\item \texttt{val\_loss} monitorata
     		\end{itemize}
     		\item Decaying learning rate di \\ $exp(-0.15)$ dopo la prima epoca
		\end{itemize}
    \end{minipage}
    \end{tabular}
\end{frame}

\section{Conversione in modelli TFLite}
\begin{frame}
	\frametitle{Conversione in modelli TFLite}
	
	\begin{itemize}
		\item Dopo la definizione del modello e il suo addestramento, è possibile
		convertire il modello in tflite e avviare la quantizzazione.
	
		\item Nel progetto vengono provati tutti e 3 i livelli di quantizzazione offerti.
	
		\item Il modello viene salvato sul filesystem e quindi sarà possibile effettuare
		la valutazione in seguito usando le utils di \texttt{tf.lite} per caricare il modello
		in memoria e istanzizare un \texttt{tf.lite.Interpreter} su cui chiamare il metodo
		\texttt{invoke} per fare inferenza.
	
		\item Data l'immediatezza di utilizzo, non è necessario effettuare nessuna azione sul modello originale,
		pre o post quantizzazione, si può direttamente procedere con l'evaluation che ne risalterà i vantaggi
	\end{itemize}
	
\end{frame}

\section{Evaluation dei modelli}
\begin{frame}
    \frametitle{Evaluation dei modelli}
    
    Dopo la validazione dei modelli (cambiando l'input shape, il batch size, 
    il decaying lr, il dropout e/o l'architettura di rete in generale) l'evaluation finale
    (sul testing set) viene effettuata tenendo conto sia del costo computazionale che 
    dell'accuracy del modello.
    
    \dflvspace
    
    Dato l'obiettivo dell'evaluation e:
    \begin{itemize}
    		\item il fatto che vogliamo una stima dei costi che rifletta l'utilizzo reale
    		\item il fatto che l'evaluate di tf/keras non fornisce informazioni affidabili sul tempo di inferenza
    		\item l'evaluate di tf/keras processa elementi in batch
    		\item l'utilizzo del profiler di tf non è necessario per il task
    		\item il fatto che per tflite non esiste un metodo/funzione che misuri le prestazioni del modello,
    		sia per quanto riguarda l'accuratezza che i costi computazionali\dots
    		\item \dots e quindi bisogna scrivere una funzione di evaluate da zero per tflite
	\end{itemize}
\end{frame}

\subsection{Metodo evaluate}
\begin{frame}
	\frametitle{Metodo evaluate}
	
	E' risultato conveniente scrivere un metodo evaluate univoco che misurasse loss, accuracy, inference time
	allo stesso modo sia per modelli tf/keras che tflite.
	
	\dflvspace
	
	Per la loss e l'accuracy si utilizzano le classi:
	\begin{itemize}
		\item \texttt{keras.losses.CategoricalCrossentropy}
		\item \texttt{keras.metrics.CategoricalAccuracy}
	\end{itemize}
	in modalità standalone: aggregando e calcolando i risultati al termine (o in iterazione intermedia per logging).
	
	\dflvspace
	
	Per riflettere l'utilizzo reale del modello, ai modelli tf viene passato un singolo elemento del testing set,
	invocato il metodo \texttt{keras.Model.\_\_call\_\_} e quindi misurato il tempo di inferenza con un timer ad alta
	risoluzione (\texttt{time.perf\_counter}). Stessa cosa per i modelli tflite, solo che viene invocato il metodo
	\texttt{tf.lite.Interpreter.invoke} invece che la \texttt{\_\_call\_\_}. Dall'accumulo dei tempi di inferenza,
	si ricava facilmente il tempo di inferenza medio.
\end{frame}

\section{Risultati ottenuti}
\begin{frame}
    \frametitle{Risultati ottenuti}
    
    \fontsize{6pt}{7pt}\selectfont
    
    \begin{center}
    % grandezza del modello ottenuta leggendo la grandezza del file dei pesi /modello tflite con funzione os.file....
    \begin{tabular} { c c c }
    		
    		\begin{minipage}[t]{0.37\linewidth}
    		\textbf{Loss e accuracy}
    		
    		\begin{tabular}{ | r | c | c | }
    		\hline
    		& \texttt{MN} & \texttt{IRNV2} \\
    		\hline
    		\hline
    		\textbf{NQ} & 0.1141, 0.9650 & 0.0804, 0.9805 \\
    		\hline
    		\textbf{TL} & 0.1141, 0.9650 & 0.0804, 0.9805 \\
    		\hline
    		\textbf{DR} & 0.1195, 0.9617 & 0.0807, 0.9803 \\
    		\hline
    		\textbf{FF} & 0.1492, 0.9608 & 0.1028, 0.9803 \\
    		\hline
    		\textbf{IO} & 0.1473, 0.9604 & 0.1034, 0.9795 \\
    		\hline
    		\end{tabular}
    		\end{minipage}
    		
    		&
    		
    		\begin{minipage}[t]{0.24\linewidth}
    		\textbf{Avg. inference time}
    		
    		\begin{tabular}{ | r | c | c | }
    		\hline
    		& \texttt{MN} & \texttt{IRNV2} \\
    		\hline
    		\hline
    		\textbf{NQ} & 60 ms & 581 ms \\
    		\hline
    		\textbf{TL} & 28 ms & 314 ms \\
    		\hline
    		\textbf{DR} & 35 ms & 308 ms \\
    		\hline
    		\textbf{FF} & 28 ms & 278 ms \\
    		\hline
    		\textbf{IO} & 28 ms & 279 ms \\
    		\hline
    		\end{tabular}
    		\end{minipage}
    		
    		&
    		
    		\begin{minipage}[t]{0.35\linewidth}
    		\textbf{Size [\texttt{get\_file\_size(weights\_file)}]}
    		
    		\begin{tabular}{ | r | c | c | }
    		\hline
    		& \texttt{MN} & \texttt{IRNV2} \\
    		\hline
    		\hline
    		\textbf{NQ} & 12.67 MB & 209.34 MB \\
    		\hline
    		\textbf{TL} & 12.25 MB & 207.24 MB\\
    		\hline
    		\textbf{DR} & 3.24 MB & 53.01 MB \\
    		\hline
    		\textbf{FF} & 3.36 MB & 53.90 MB \\
    		\hline
    		\textbf{IO} & 3.36 MB & 53.90 MB \\
    		\hline
    		\end{tabular}
    		\end{minipage}
	\end{tabular}
	\end{center}
	
	\dflvspace
	
	\fontsize{10pt}{11pt}\selectfont
	
	Per entrambi i casi:
	\begin{itemize}
		\item Dimezzamento dei tempi di inferenza
			\begin{itemize}
				\item Anche solo convertendo i modelli keras in tflite
			\end{itemize}
		\item $\displaystyle{\frac{1}{4}}$ della size originale
		\item Prestazioni di accuratezza quasi intatte
			\begin{itemize}
				\item \texttt{InceptionResNetV2} subisce meno l'effetto della quantizzazione sull'accuratezza
			\end{itemize}
	\end{itemize}
	
	\dflvspace
	
	In conclusione, \texttt{MobileNet} è la scelta migliore per tempi di inferenza, grandezza del modello e accuratezza 
	(quel $<2\%$ in più non vale la pena), in particolare con quantizzazione integer-only.
\end{frame}

\begin{frame}
    \frametitle{}
    
    \fontsize{30pt}{10pt}\selectfont
    \centering
    \textbf{Grazie per l'attenzione!}
    
\end{frame}

\end{document}